{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa00e7b-1f93-4872-b1d3-c7c758329688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os, os.path\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from os import walk\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pathlib\n",
    "import glob\n",
    "import splitfolders\n",
    "import random\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorboard\n",
    "import SimpleITK as sitk\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f1116-0f7d-4078-acf4-c35f84d92f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'Sarcoidosis AI (287 patients to 09-2023) - clusters.csv'\n",
    "data_ = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b2ad7-32ba-4908-b61c-84c76cc7a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_[['Study']]  # Seleziona solo la colonna 'Study'\n",
    "labels = data_['Systemic Sarcoidosis (POSITIVE = 1)']  # Utilizza solo la label per la sarcoidosi sistemica\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88c707-1bdd-43d5-ac3a-267e726ae472",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'sarcoidosis_MIPs_(npy)'\n",
    "# List to save data loaded from each numpy file\n",
    "data_list = []\n",
    "new_height=400 \n",
    "new_width=200\n",
    "# Scan folder and load each numpy file\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.npy'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        data = np.load(file_path)\n",
    "        image=[]\n",
    "        slice1=data[0]\n",
    "        #slice2=data[3]\n",
    "        #slice3=data[5]\n",
    "        #slice4=data[7]\n",
    "\n",
    "        # Crop before resizing        \n",
    "        resized_slice1 = cv2.resize(slice1, (new_width, new_height))\n",
    "        #resized_slice2 = cv2.resize(slice2, (new_width, new_height))\n",
    "        #resized_slice3 = cv2.resize(slice3, (new_width, new_height))\n",
    "        #resized_slice4 = cv2.resize(slice4, (new_width, new_height))\n",
    "\n",
    "        # Crop to the resized image\n",
    "        cropped_slice1 = resized_slice1[60:300, 20:200]\n",
    "        #cropped_slice2 = resized_slice2[50:370, :200]\n",
    "        #cropped_slice3 = resized_slice3[50:370, :200]\n",
    "        #cropped_slice4 = resized_slice4[50:370, :200]\n",
    "\n",
    "            #cropped_slice=cropped_slice / 255.0\n",
    "        #image.append(cropped_slice1)\n",
    "        #image.append(cropped_slice2)\n",
    "        #image.append(cropped_slice3)\n",
    "        #image.append(cropped_slice4)\n",
    "        study_id = int(filename.split('_')[0])\n",
    "       # Initialize a list to store matching labels\n",
    "        matching_labels = []\n",
    "\n",
    "        # ID patient\n",
    "\n",
    "        # Find the corresponding patient label in the DataFrame\n",
    "        matching_label = data_[data_['Study'] == study_id]['Systemic Sarcoidosis (POSITIVE = 1)'].values\n",
    "        if len(matching_label) > 0:\n",
    "            matching_labels.append(matching_label[0])\n",
    "        else:\n",
    "            matching_labels.append(None)  \n",
    "            \n",
    "    \t# Add the corresponding patient image and label to the data list\n",
    "        data_list.append((np.array(cropped_slice1), matching_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789aaac-08c9-415e-9f1d-c0f994eb1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data_list:\n",
    "    image_array, label = item  \n",
    "print(\"Image shape:\", image_array.shape)  \n",
    "print(\"Label:\", label) \n",
    "print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf757f1-bc9f-4255-b19a-e33c346a7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializza le liste per le features e le label\n",
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Estrai le features e le label da data_list\n",
    "for item in data_list:\n",
    "    features, label = item\n",
    "    features_list.append(features)\n",
    "    labels_list.append(label)\n",
    "\n",
    "# Converti le liste in array numpy\n",
    "features_array = np.array(features_list)\n",
    "labels_array = np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1517f0-ca16-46ee-9579-c61719aa741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(features_array))\n",
    "plt.imshow(features_array[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09deb899-1a8a-4ac3-b63e-14ddf9df9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(features_array))\n",
    "image=(features_array[98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf09a4-44ef-4ad8-91cc-a303ffc7fc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01de785-4ea0-4523-81bc-efe70cccc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_grad_cam(model, layer_name, image):\n",
    "    # Create a graph that outputs target convolution and output\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
    "\n",
    "    # Get the score for target class\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.array([image]))\n",
    "        loss = predictions[0]\n",
    "\n",
    "    # Extract filters and gradients\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    # Average gradients spatially\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    # Build a ponderated map of filters according to gradients importance\n",
    "    cam = np.ones(output.shape[0:2], dtype=np.float32)\n",
    "\n",
    "    for index, w in enumerate(weights):\n",
    "        cam += w * output[:, :, index]\n",
    "\n",
    "    # Heatmap visualization\n",
    "    cam = cv2.resize(cam.numpy(), (180, 240))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295a1ea-bcad-4902-829e-06b87c06d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definition of the number of folds for cross-validation\n",
    "n_splits =5\n",
    "input_shape = (240, 180, 3)  \n",
    "\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(n_splits):\n",
    "    print(f\"Iterazione {i+1}:\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_array, labels_array, test_size=0.3, random_state=i, stratify=labels_array)\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.30, random_state=i, stratify=y_test)\n",
    "\n",
    "    # Data augmentation\n",
    "    def saturate_image(image):\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        hsv_image[..., 1] *= np.random.uniform(0.5, 1.5)  \n",
    "        return cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    def adjust_contrast(image, factor):\n",
    "        return tf.image.adjust_contrast(image, factor)\n",
    "\n",
    "    def custom_contrast(image):\n",
    "        factor = tf.random.uniform([], 0.4, 1)  \n",
    "        return adjust_contrast(image, factor)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=custom_contrast\n",
    "        #vertical_flip=True,\n",
    "        #brightness_range=[0.2, 0.5]\n",
    "        \n",
    "        \n",
    "    )\n",
    "\n",
    "   # Creation of the complete model\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Imposta i layer come non allenabili\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "   # Create a new sequential pattern\n",
    "    x = Flatten()(vgg16.output)\n",
    "    x = Dense(512, activation='relu' ,kernel_regularizer=l1(0.001))(x)\n",
    "    x = Dropout(0.3)(x)  # Aggiungi un layer di Dropout con una probabilità del 50%\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=vgg16.input, outputs=predictions)\n",
    "    model.summary()\n",
    "\n",
    "    X_train = X_train / 255\n",
    "    X_val = X_val / 255\n",
    "    X_test = X_test / 255\n",
    "\n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "\n",
    "    model.compile(optimizer=Adamax(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_generator, epochs=50, validation_data=(X_val, y_val))\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_predictions = (test_predictions > 0.5).astype(int)\n",
    "    f1 = f1_score(y_test, test_predictions)\n",
    "    print(\"F1-score:\", f1)\n",
    "\n",
    "    accuracy_scores.append(test_accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # GRAD-CAM\n",
    "    conv_layer = 'block5_conv3'\n",
    "    num_images_to_display = min(len(X_test), 30)  \n",
    "    rows = int(np.ceil(num_images_to_display / 5))  \n",
    "\n",
    "    plt.figure(figsize=(15, 3 * rows))  \n",
    "    for i in range(num_images_to_display):\n",
    "        cam = calculate_grad_cam(model, conv_layer, X_test[i])\n",
    "        plt.subplot(rows, 5, i+1)\n",
    "        plt.imshow(X_test[i])\n",
    "        plt.imshow(cam, alpha=0.5, cmap='jet')\n",
    "        title = \"Correct\" if test_predictions[i] == y_test[i] else \"Incorrect\"\n",
    "        title += f\" (Class {y_test[i]})\"  \n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Average Accuracy:\", np.median(accuracy_scores))\n",
    "print(\"Average F1-score:\", np.median(f1_scores))\n",
    "print(\"Standard Deviation of Accuracy:\", np.std(accuracy_scores))\n",
    "print(\"Standard Deviation of F1-score:\", np.std(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c739c4-52be-4543-863a-def60cd07a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Average F1-score:\", np.mean(f1_scores))\n",
    "print(\"Standard Deviation of Accuracy:\", np.std(accuracy_scores))\n",
    "print(\"Standard Deviation of F1-score:\", np.std(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359aa520-b841-4600-8c74-2f64e95b72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(accuracy_scores,25))\n",
    "print(np.percentile(f1_scores,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b99841-1980-43d0-af77-d2bd355d0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(accuracy_scores,75))\n",
    "print(np.percentile(f1_scores,75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc5786-6213-4298-b11c-7fb2d52fea05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf90501-eee2-4507-8b2e-d80b6ce7c0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
